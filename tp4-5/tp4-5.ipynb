{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tp2.utils import display_tracking_results, save_tracking_results, parse_seqinfo, parse_file_pd\n",
    "from tp2.compute import ObjectInstance, iou_jaccard, compute_similarity_matrix, hungarian_algorithm\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "probleme person are confused with each other, i tried to change the normalization from constent to std and mean from the frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_patch(im_crops, width=64, height=128):\n",
    "        # constantes\n",
    "\n",
    "        roi_means = np.array([123.675, 116.28, 103.53], dtype=np.float32)\n",
    "        roi_stds = np.array([58.395, 57.12, 57.375], dtype=np.float32)\n",
    "\n",
    "        roi_input = cv2.resize(im_crops, (width, height)) \n",
    "        roi_input = cv2.cvtColor(roi_input, cv2.COLOR_BGR2RGB)\n",
    "        std = np.std(roi_input)\n",
    "        mean = np.mean(roi_input)\n",
    "        roi_input = (np.asarray(roi_input).astype(np.float32)  -  mean) / std\n",
    "        roi_input = np.moveaxis(roi_input, -1, 0) \n",
    "        object_patch = roi_input.astype('float32') \n",
    "        return object_patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import onnxruntime as rt\n",
    "def get_model(model_path):\n",
    "    onnx_model = onnx.load(model_path)\n",
    "\n",
    "    # Check the model for consistency\n",
    "    onnx.checker.check_model(onnx_model)\n",
    "    return onnx_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "problem with model input, forgot to unsqueeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tracker:\n",
    "    def __init__(self, frame, obj_id, bb_left, bb_top, bb_width, bb_height,):\n",
    "        self.frame = int(frame)\n",
    "        self.obj_id = int(obj_id)\n",
    "        self.bb_left = float(bb_left)\n",
    "        self.bb_top = float(bb_top)\n",
    "        self.bb_width = float(bb_width)\n",
    "        self.bb_height = float(bb_height)\n",
    "        # self.conf = float(conf)\n",
    "        # self.coord = float(x), float(y), float(z)\n",
    "\n",
    "        self.feature = []\n",
    "    \n",
    "    def generate_feature(self, session, frame):\n",
    "\n",
    "        y_end = int(self.bb_top + self.bb_height)\n",
    "        x_end = int(self.bb_left + self.bb_width)\n",
    "        x_start = int(self.bb_left)\n",
    "        y_start = int(self.bb_top)\n",
    "        image = frame[y_start:y_end, x_start:x_end]\n",
    "\n",
    "        # Preprocess the image\n",
    "        image = preprocess_patch(image)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            input_data = torch.from_numpy(image).unsqueeze(0)\n",
    "            input_data = input_data.numpy()\n",
    "\n",
    "            input_name = session.get_inputs()[0].name\n",
    "            feature = session.run(None, {input_name: input_data})[0]\n",
    "            self.feature = feature[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_euclidean_distance_matrix(tracked : list[Tracker], detected : list[Tracker] ):\n",
    "    distance_matrix = np.zeros((len(tracked), len(detected)))\n",
    "    for i, track in enumerate(tracked):\n",
    "        for j, detect in enumerate(detected):\n",
    "            distance_matrix[i, j] = 1 / (1 + (track.feature - detect.feature))\n",
    "    return distance_matrix\n",
    "\n",
    "\n",
    "def cosine_similarity(tracked : list[Tracker], detected : list[Tracker] ):\n",
    "    distance_matrix = np.zeros((len(tracked), len(detected)))\n",
    "    for i, track in enumerate(tracked):\n",
    "        for j, detect in enumerate(detected):\n",
    "            distance_matrix[i, j] = np.dot(track.feature, detect.feature) / (np.linalg.norm(track.feature) * np.linalg.norm(detect.feature))\n",
    "    return distance_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "probleme with echange of id when object goes in front of other (change alpha and beta, lost frame, threshold (hyperparameter))\n",
    "probleme with object getting old id (same hyper parameter search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 0.5\n",
    "MAX_LOST_FRAMES = 50\n",
    "ALPHA = 0.3\n",
    "BETA = 0.7\n",
    "\n",
    "# manage the tracking\n",
    "def track_management(detected_objects : pd.DataFrame, data_path : str, model_path: str) -> pd.DataFrame:\n",
    "    \n",
    "    # video settings\n",
    "    seq_info = parse_seqinfo(data_path)\n",
    "    video_path = os.path.join(data_path, 'img1')\n",
    "    frame_length = int(seq_info['seqLength'])\n",
    "    # frame_length = 10 # for testing\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    session = rt.InferenceSession(model_path,providers=rt.get_available_providers())\n",
    "\n",
    "    # initialize tracked objects\n",
    "    tracked_objects = []\n",
    "    # initialize results with pandas frame\n",
    "    results = pd.DataFrame(columns=['frame', 'id', 'bb_left', 'bb_top', 'bb_width', 'bb_height', 'conf', 'x', 'y', 'z'])\n",
    "\n",
    "    idx = 1\n",
    "    all_matrix = []\n",
    "    # iter over frames\n",
    "    for frame_idx in tqdm(range(1,frame_length + 1)):\n",
    "        new_tracks = []\n",
    "\n",
    "        # Get detected objects on frame\n",
    "        detected_obj_on_frame = detected_objects[detected_objects['frame'] == frame_idx]\n",
    "        # no object detected on frame\n",
    "        if detected_obj_on_frame.empty:\n",
    "            for track in tracked_objects:\n",
    "                if track.frame > frame_idx - MAX_LOST_FRAMES:\n",
    "                    new_tracks.append(track)\n",
    "\n",
    "        # atleast one object detected on frame\n",
    "        else:\n",
    "            # get frame\n",
    "            frame = cv2.imread(os.path.join(video_path, f'{frame_idx:06d}.jpg'))\n",
    "\n",
    "            # Create ObjectInstance objects\n",
    "            detected_obj_on_frame = [Tracker(*obj) for obj in detected_obj_on_frame.values]\n",
    "\n",
    "            # generate features for each object\n",
    "            for obj in detected_obj_on_frame:\n",
    "                obj.generate_feature(session, frame)\n",
    "\n",
    "            # compute similarity matrix and matches\n",
    "            similarity_matrix = compute_similarity_matrix(tracked_objects, detected_obj_on_frame)\n",
    "            cosine_similarity_matrix = cosine_similarity(tracked_objects, detected_obj_on_frame)\n",
    "\n",
    "            cost_matrix = ALPHA * similarity_matrix + BETA * cosine_similarity_matrix\n",
    "            \n",
    "            matches = hungarian_algorithm(cost_matrix)\n",
    "\n",
    "            # update tracks\n",
    "            matched_detections = []\n",
    "            matched_tracks = []\n",
    "            matrix = []\n",
    "            for i, j in matches:\n",
    "                # matched track\n",
    "                matrix.append(cost_matrix[i][j])\n",
    "                if cost_matrix[i][j] >= THRESHOLD:\n",
    "                    matched_detections.append(j)\n",
    "                    matched_tracks.append(i)\n",
    "                    # save track \n",
    "                    old_track = tracked_objects[i]\n",
    "                    # update track information\n",
    "                    detected_obj_on_frame[j].obj_id = old_track.obj_id\n",
    "                    new_tracks.append(detected_obj_on_frame[j])\n",
    "\n",
    "            # remove old tracks\n",
    "            for i in range(len(tracked_objects)):\n",
    "                if i not in matched_tracks:\n",
    "                    if tracked_objects[i].frame > frame_idx - MAX_LOST_FRAMES:\n",
    "                        new_tracks.append(tracked_objects[i])\n",
    "            \n",
    "            # add unmatched detections as new tracks\n",
    "            for i in range(len(detected_obj_on_frame)):\n",
    "                if i not in matched_detections:\n",
    "                    new_tracks.append(detected_obj_on_frame[i])\n",
    "                    new_tracks[-1].obj_id = idx\n",
    "                    idx += 1\n",
    "            all_matrix.append(matrix)\n",
    "\n",
    "        # update results\n",
    "        for track in new_tracks:\n",
    "            track_df = pd.DataFrame([{'frame': track.frame, 'id': track.obj_id, 'bb_left': track.bb_left, 'bb_top': track.bb_top, 'bb_width': track.bb_width, 'bb_height': track.bb_height, 'conf': 1, 'x': -1, 'y': -1, 'z': -1}])\n",
    "            results = pd.concat([results, track_df], ignore_index=True)\n",
    "\n",
    "        # update old tracked objects with updated tracked objects\n",
    "        tracked_objects = new_tracks\n",
    "\n",
    "    # sort over frame and id\n",
    "    results.sort_values(by=['frame', 'id'], inplace=True)\n",
    "    return results, all_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the data\n",
    "data_path = \"/home/gautier/scia2/mlvot/ADL-Rundle-6\"\n",
    "\n",
    "# sequences names\n",
    "sequence_public = \"public-dataset\"\n",
    "sequence_yolo5l = \"Yolov5l\"\n",
    "sequence_yolo5s = \"Yolov5s\"\n",
    "\n",
    "# create the path to the file\n",
    "file = f\"det/{sequence_yolo5l}/det.txt\"\n",
    "file_path = os.path.join(data_path, file)\n",
    "\n",
    "# model path\n",
    "model_path = \"/home/gautier/scia2/mlvot/tp4-5/Filemail.com - TP4 et TP5/reid_osnet_x025_market1501.onnx\"\n",
    "\n",
    "# parse the file\n",
    "parsed_objects_pd = parse_file_pd(file_path, ' ')\n",
    "parsed_objects_pd.drop(columns=['conf', 'x', 'y', 'z'], inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/525 [00:00<?, ?it/s]/tmp/ipykernel_5503/1415123249.py:92: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results = pd.concat([results, track_df], ignore_index=True)\n",
      "100%|██████████| 525/525 [00:43<00:00, 11.98it/s]\n"
     ]
    }
   ],
   "source": [
    "results, all_matrix = track_management(parsed_objects_pd, data_path=data_path, model_path=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_tracking_results(results : pd.DataFrame, data_path : str, output_path : str):\n",
    "    # parse seqinfo\n",
    "    seq_info = parse_seqinfo(data_path)\n",
    "\n",
    "    video_path = os.path.join(data_path, 'img1')\n",
    "\n",
    "    # Configure video reader\n",
    "    frame_width = int(seq_info['imWidth'])\n",
    "    frame_height = int(seq_info['imHeight'])\n",
    "    frame_length = int(seq_info['seqLength'])\n",
    "    # frame_length = 10\n",
    "    fps = int(seq_info['frameRate'])\n",
    "    \n",
    "    \n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))    \n",
    "\n",
    "    # get results\n",
    "    # results = track_management(tracked_object, frame_length)\n",
    "\n",
    "    # draw bounding boxes\n",
    "    for frame_idx in range(1, frame_length + 1):\n",
    "        frame = cv2.imread(os.path.join(video_path, f'{frame_idx:06d}.jpg'))\n",
    "        tracks = results[results['frame'] == frame_idx]\n",
    "        for track in tracks.values:\n",
    "            x, y, w, h = track[2:6]\n",
    "            cv2.rectangle(frame, (int(x), int(y)), (int(x + w), int(y + h)), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, str(int(track[1])), (int(x), int(y) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "        cv2.imshow('frame', frame)\n",
    "        out.write(frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = 'output.mp4'\n",
    "display_tracking_results(results, data_path, output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlvot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
